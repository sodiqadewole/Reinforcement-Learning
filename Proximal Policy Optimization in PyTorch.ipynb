{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZTf22Z0qMP2"
      },
      "outputs": [],
      "source": [
        "!pip install torchrl\n",
        "!pip install gym[mujoco]\n",
        "!pip install tqdm\n",
        "!pip install \"gymnasium[mujoco]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from torch import multiprocessing\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torch import nn\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter, TransformedEnv)\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "QtmdMnjzYHfP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Hyperparameters"
      ],
      "metadata": {
        "id": "i5vwGaBuaf1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_fork = multiprocessing.get_start_method(allow_none=True) == \"fork\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_cells = 256\n",
        "lr = 3e-4\n",
        "max_grad_norm = 1.0"
      ],
      "metadata": {
        "id": "Lze8auJVYHbj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_per_batch = 1000\n",
        "# Total number of frames for complete training up to 1M\n",
        "total_frames = 50_000"
      ],
      "metadata": {
        "id": "CFS1ItLfYHYY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PPO Parameters\n",
        "\n",
        "At each data collection (or batch collection) we will run the optimization over a certain numer of epochs, each time consuming the entire data we just acquired in a nested training loop."
      ],
      "metadata": {
        "id": "e-3SIv77bZKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_batch_size = 64 # sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 10 # optimizations steps per batch of data collected\n",
        "clip_epsilon = (0.2) # Clip value for PPO loss\n",
        "gamma = 0.99\n",
        "lmbda = 0.95\n",
        "entropy_loss = 1e-4"
      ],
      "metadata": {
        "id": "nVUIp6imYHVk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the environment"
      ],
      "metadata": {
        "id": "m-7z4xlPcEL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymEnv(\"InvertedDoublePendulum-v4\", device=device) #(\"Ant-v4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db_xLUrwYHTA",
        "outputId": "db322adc-accd-4089-93ef-e88d34f05a46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment transforms and normalization"
      ],
      "metadata": {
        "id": "YwDwOIm8kAKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # normalize observations\n",
        "        ObservationNorm(in_keys=[\"observation\"]),\n",
        "        DoubleToFloat(),\n",
        "        StepCounter(),\n",
        "    )\n",
        ")\n",
        "\n",
        "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
        "print(\"Normalization constant shape:\", env.transform[0].loc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-SIfykhYHP8",
        "outputId": "f4bd3181-01e8-4d83-d3f1-ab8e55b4a0e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization constant shape: torch.Size([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Observation_spec:\", env.observation_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAikkIRAYHMf",
        "outputId": "d537a2f0-b0a1-4de6-90f0-20e1d9ed7254"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation_spec: Composite(\n",
            "    observation: UnboundedContinuous(\n",
            "        shape=torch.Size([11]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    step_count: BoundedDiscrete(\n",
            "        shape=torch.Size([1]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True)),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.int64,\n",
            "        domain=discrete),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([]),\n",
            "    data_cls=None)\n",
            "reward_spec: UnboundedContinuous(\n",
            "    shape=torch.Size([1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "    device=cuda:0,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "        step_count: BoundedDiscrete(\n",
            "            shape=torch.Size([1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.int64,\n",
            "            domain=discrete),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([]),\n",
            "        data_cls=None),\n",
            "    full_action_spec: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([]),\n",
            "        data_cls=None),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([]),\n",
            "    data_cls=None)\n",
            "action_spec (as defined by input_spec): BoundedContinuous(\n",
            "    shape=torch.Size([1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "    device=cuda:0,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYxeC4-7nSM1",
        "outputId": "80b95bf6-41b1-40d5-a4f4-9e6b1e8e0d58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m2025-09-22 06:23:40,267 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rollout sample number of steps from the environment\n",
        "n_steps = 5\n",
        "rollout = env.rollout(n_steps)\n",
        "print(\"rollout of 5 steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tStxWRnMnSHy",
        "outputId": "1671d109-c02a-4b5d-9230-636575e12a84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rollout of 5 steps: TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([5, 11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([5]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        observation: Tensor(shape=torch.Size([5, 11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([5]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Shape of the rollout TensorDict: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Policy"
      ],
      "metadata": {
        "id": "4U_iHPIE_ECN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(2 * env.action_spec.shape[-1], device=device),\n",
        "    NormalParamExtractor(),\n",
        ")\n",
        "\n",
        "policy_module = TensorDictModule(actor_net,\n",
        "                                 in_keys=[\"observations\"],\n",
        "                                 out_keys=[\"loc\", \"scale\"])\n",
        "\n",
        "policy_module = ProbabilisticActor(\n",
        "    module = policy_module,\n",
        "    spec = env.action_spec,\n",
        "    in_keys = [\"loc\", \"scale\"],\n",
        "    distribution_class = TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"low\": env.action_spec.space.low,\n",
        "        \"high\": env.action_spec.space.high,\n",
        "    },\n",
        "    return_log_prob = True,\n",
        ")"
      ],
      "metadata": {
        "id": "sQx4QSypnSC3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Network\n",
        "\n",
        "value_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(1, device=device),\n",
        ")\n",
        "\n",
        "value_module = ValueOperator(module=value_net, in_keys=[\"observation\"])\n",
        "\n",
        "# Try the policy and value modules\n",
        "print(\"Running policy:\", policy_module(env.reset()))\n",
        "print(\"Running value:\", value_module(env.reset()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "z1e6thDbnR9f",
        "outputId": "c1299104-85db-4890-c9d6-af98fa9c8a0a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Some tensors that are necessary for the module call may not have not been found in the input tensordict: the following inputs are None: {'observations'}.\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: TensorDictModule failed with operation\n    Sequential(\n      (0): LazyLinear(in_features=0, out_features=256, bias=True)\n      (1): Tanh()\n      (2): LazyLinear(in_features=0, out_features=256, bias=True)\n      (3): Tanh()\n      (4): LazyLinear(in_features=0, out_features=256, bias=True)\n      (5): Tanh()\n      (6): LazyLinear(in_features=0, out_features=2, bias=True)\n      (7): NormalParamExtractor(\n        (scale_mapping): biased_softplus()\n      )\n    )\n    in_keys=['observations']\n    out_keys=['loc', 'scale'].",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3108121097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Try the policy and value modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running policy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running value:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_self\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/probabilistic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m                     ) from e\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             \u001b[0mtensordict_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict_exec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m             tensordict_exec = self._last_module(\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mtensordict_exec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_requires_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requires_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/probabilistic.py\u001b[0m in \u001b[0;36mget_dist_params\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find a default interaction in the modules.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mset_interaction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_self\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/sequence.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     tensordict_exec = self._run_module(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict_exec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/sequence.py\u001b[0m in \u001b[0;36m_run_module\u001b[0;34m(self, module, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         ):\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_tolerant\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyStackedTensorDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msub_td\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_self\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0m_skip_existing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0min_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"in_keys={self.in_keys}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0mout_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"out_keys={self.out_keys}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             raise err from RuntimeError(\n\u001b[0m\u001b[1;32m   1219\u001b[0m                 \u001b[0;34mf\"TensorDictModule failed with operation\\n{module}\\n{in_keys}\\n{out_keys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensordict/nn/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                     }\n\u001b[0;32m-> 1184\u001b[0;31m                     raise KeyError(\n\u001b[0m\u001b[1;32m   1185\u001b[0m                         \u001b[0;34m\"Some tensors that are necessary for the module call may \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                         \u001b[0;34m\"not have not been found in the input tensordict: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Some tensors that are necessary for the module call may not have not been found in the input tensordict: the following inputs are None: {'observations'}.\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "k0dmTXDMEp1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(max_size=frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "eWdGP5WKEpsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=True, device=device,\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor_network=policy_module,\n",
        "    critic_network=value_module,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    critic_coef=1.0,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optim, total_frames // frames_per_batch, 0.0\n",
        ")"
      ],
      "metadata": {
        "id": "lhrb3UiKEpiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optimization step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel())\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our ``env`` horizon).\n",
        "        # The ``rollout`` method of the ``env`` can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.DETERMINISTIC), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "e5qsaGszEpYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjXnLJHrEzBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}